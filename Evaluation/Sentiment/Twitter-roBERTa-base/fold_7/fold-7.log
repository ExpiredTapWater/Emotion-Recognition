[2025-01-06 06:50:00,153][config.py][line:54][INFO] PyTorch version 2.4.1+cu124 available.
[2025-01-06 06:50:02,376][evaluate.py][line:185][INFO] ----- Models -----
[2025-01-06 06:50:02,376][evaluate.py][line:186][INFO] Sentiment Model: cardiffnlp/twitter-roberta-base-sentiment-latest
[2025-01-06 06:50:02,376][evaluate.py][line:187][INFO] ----- Parameters -----
[2025-01-06 06:50:02,376][evaluate.py][line:188][INFO] Seed: 22
[2025-01-06 06:50:02,376][evaluate.py][line:189][INFO] Fold: 7
[2025-01-06 06:50:02,376][evaluate.py][line:191][INFO] ----- NLP Options -----
[2025-01-06 06:50:02,376][evaluate.py][line:193][INFO] Apply Preprocessing: YES
[2025-01-06 06:50:02,376][evaluate.py][line:194][INFO] Remove Contractions: True
[2025-01-06 06:50:02,385][evaluate.py][line:195][INFO] Apply Lemmantization: True
[2025-01-06 06:50:02,385][evaluate.py][line:196][INFO] Remove Numbers: True
[2025-01-06 06:50:02,385][evaluate.py][line:197][INFO] Remove Stopwords: False
[2025-01-06 06:50:02,385][evaluate.py][line:200][INFO] --------------------
[2025-01-06 06:50:03,414][evaluate.py][line:249][INFO] Sentiment model loaded from cardiffnlp/twitter-roberta-base-sentiment-latest successfully
[2025-01-06 06:50:03,421][evaluate.py][line:306][INFO] Mode: train Fold: 7
[2025-01-06 06:50:03,429][evaluate.py][line:306][INFO] Mode: val Fold: 7
[2025-01-06 06:50:03,434][evaluate.py][line:306][INFO] Mode: test Fold: 7
[2025-01-06 06:50:03,435][evaluate.py][line:352][INFO] Dataset Loaded
[2025-01-06 06:50:07,470][evaluate.py][line:461][INFO] Done processing 504 files
[2025-01-06 06:50:07,472][evaluate.py][line:472][INFO] Predictions saved to ./fold_7\predictions.csv
[2025-01-06 06:50:07,482][evaluate.py][line:488][INFO] Now calculating accuracy
[2025-01-06 06:50:07,490][evaluate.py][line:525][INFO] Test UA: 0.5115709003874768
[2025-01-06 06:50:07,490][evaluate.py][line:527][INFO] Confusion Matrix:
[2025-01-06 06:50:07,493][evaluate.py][line:528][INFO] 
          negative  neutral  positive
negative        85       39        24
neutral         84      113        36
positive        34       30        58
[2025-01-06 06:50:07,500][evaluate.py][line:532][INFO] Classification Report:
[2025-01-06 06:50:07,500][evaluate.py][line:533][INFO] 
              precision    recall  f1-score   support

    negative       0.42      0.57      0.48       148
     neutral       0.62      0.48      0.54       233
    positive       0.49      0.48      0.48       122

    accuracy                           0.51       503
   macro avg       0.51      0.51      0.50       503
weighted avg       0.53      0.51      0.51       503

