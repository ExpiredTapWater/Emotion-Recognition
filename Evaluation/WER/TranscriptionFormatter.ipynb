{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09769d6c-340f-4fe8-936b-205096b03e7e",
   "metadata": {},
   "source": [
    "# Notes\n",
    "- Ground truth transcription is provided in a .log file\n",
    "- When evaluating accuracy for each S2T or Sentiment model, we convert the .log file into a .csv for simplicity\n",
    "- When calculating WER, compute_wer.py wants the file in .txt, so we format it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9693a4ea-f60c-46eb-bef7-9708d674a663",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff29e93-40b0-41ec-8b95-13b7ba3a62d4",
   "metadata": {},
   "source": [
    "## Formats IEMOCAP ground truths into TXT file\n",
    "- Removes logging output\n",
    "- Keeps filename\n",
    "- Converts .log to .txt\n",
    "Which you can take from each fold folder in ./S2T-Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d590b39d-e740-48fb-a213-a97a08d4b15e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input and output file paths\n",
    "input_file = \"./InputFiles/groundtruth_IEMOCAP.log\"\n",
    "output_file = \"./OutputFiles/groundtruth_IEMOCAP.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4085e9f2-b3fd-4b20-92e8-8adf612730b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Blank transcript for: [2022-02-15 11:28:44,855][text2pickle.py][line:64][INFO] Ses01F_script01_3_F010: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:28:44,898][text2pickle.py][line:64][INFO] Ses01F_script01_3_F011: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:28:44,937][text2pickle.py][line:64][INFO] Ses01F_script01_3_F012: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:28:50,279][text2pickle.py][line:64][INFO] Ses01F_script02_2_M043: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:28:50,347][text2pickle.py][line:64][INFO] Ses01F_script02_2_M046: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:28:51,306][text2pickle.py][line:64][INFO] Ses01M_impro04_F023: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:29:13,178][text2pickle.py][line:64][INFO] Ses01M_script03_1_F007: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:29:13,286][text2pickle.py][line:64][INFO] Ses01M_script03_1_F010: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:29:17,257][text2pickle.py][line:64][INFO] Ses01F_script02_1_F009: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:29:20,435][text2pickle.py][line:64][INFO] Ses01M_script01_1_F006: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:29:24,246][text2pickle.py][line:64][INFO] Ses01F_script03_1_F020: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:29:31,711][text2pickle.py][line:64][INFO] Ses02F_impro07_F029: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:29:32,393][text2pickle.py][line:64][INFO] Ses02F_impro07_M010: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:30:14,946][text2pickle.py][line:64][INFO] Ses03F_script03_1_F000: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:30:50,116][text2pickle.py][line:64][INFO] Ses04M_impro04_F017: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:30:58,610][text2pickle.py][line:64][INFO] Ses04F_impro03_F052: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:06,601][text2pickle.py][line:64][INFO] Ses04F_impro07_F036: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:07,299][text2pickle.py][line:64][INFO] Ses04F_impro07_F064: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:07,334][text2pickle.py][line:64][INFO] Ses04F_impro07_F065: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:33,639][text2pickle.py][line:64][INFO] Ses05F_impro06_F004: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:34,041][text2pickle.py][line:64][INFO] Ses05F_impro06_F015: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:34,375][text2pickle.py][line:64][INFO] Ses05F_impro06_F024: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:34,483][text2pickle.py][line:64][INFO] Ses05F_impro06_F027: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:38,013][text2pickle.py][line:64][INFO] Ses05F_impro07_F033: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:51,939][text2pickle.py][line:64][INFO] Ses05F_impro03_F036: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:52,084][text2pickle.py][line:64][INFO] Ses05F_impro03_F041: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:52,631][text2pickle.py][line:64][INFO] Ses05F_impro03_F060: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:53,336][text2pickle.py][line:64][INFO] Ses05F_impro03_M035: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:53,450][text2pickle.py][line:64][INFO] Ses05F_impro03_M038: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:53,926][text2pickle.py][line:64][INFO] Ses05F_impro03_M060: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:57,685][text2pickle.py][line:64][INFO] Ses05M_impro02_F024: \n",
      "\n",
      "Formatted ground truth saved to ./OutputFiles/groundtruth_IEMOCAP.txt\n"
     ]
    }
   ],
   "source": [
    "# Open the input file and process each line\n",
    "with open(input_file, mode=\"r\", encoding=\"utf-8\") as infile:\n",
    "    with open(output_file, mode=\"w\", encoding=\"utf-8\") as outfile:\n",
    "        for line in infile:\n",
    "            # Use regex to extract the ID and transcript\n",
    "            match = re.search(r\"(\\S+): (.+)\", line)\n",
    "            if match:\n",
    "                # Extract ID and transcript\n",
    "                utterance_id = match.group(1)  # The ID (e.g., Ses01F_script01_3_F000)\n",
    "                transcript = match.group(2).strip()  # The transcript\n",
    "\n",
    "                # Write the formatted line to the output file\n",
    "                outfile.write(f\"{utterance_id} {transcript}\\n\")\n",
    "                \n",
    "            # Audio has no transcript\n",
    "            else:\n",
    "                print(f\"Note: Blank transcript for: {line}\")\n",
    "                match_2 = re.search(r\"\\[INFO\\]\\s+(\\S+:)\", line)\n",
    "                utterance_id = match_2.group(1)\n",
    "                outfile.write(f\"{utterance_id[:-1]} \\n\") #[:-1] prevents writing the \":\"\n",
    "\n",
    "print(f\"Formatted ground truth saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531c416c-b0ce-4eec-9927-1d28803b0930",
   "metadata": {},
   "source": [
    "## Formats IEMOCAP ground truths to CSV file\n",
    "- Removes logging output\n",
    "- Keeps filename\n",
    "- Converts .log to .csv\n",
    "Which you can take from each fold folder in ./S2T-Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6a7d7ef4-1d2a-44f7-8807-be887fb05069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input and output file paths\n",
    "input_file = \"./InputFiles/groundtruth_IEMOCAP.log\"\n",
    "output_csv = \"./OutputFiles/groundtruth_IEMOCAP.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "93bb1db4-285b-46b5-b255-98b1b7565b24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Blank transcript for: [2022-02-15 11:28:44,855][text2pickle.py][line:64][INFO] Ses01F_script01_3_F010: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:28:44,898][text2pickle.py][line:64][INFO] Ses01F_script01_3_F011: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:28:44,937][text2pickle.py][line:64][INFO] Ses01F_script01_3_F012: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:28:50,279][text2pickle.py][line:64][INFO] Ses01F_script02_2_M043: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:28:50,347][text2pickle.py][line:64][INFO] Ses01F_script02_2_M046: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:28:51,306][text2pickle.py][line:64][INFO] Ses01M_impro04_F023: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:29:13,178][text2pickle.py][line:64][INFO] Ses01M_script03_1_F007: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:29:13,286][text2pickle.py][line:64][INFO] Ses01M_script03_1_F010: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:29:17,257][text2pickle.py][line:64][INFO] Ses01F_script02_1_F009: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:29:20,435][text2pickle.py][line:64][INFO] Ses01M_script01_1_F006: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:29:24,246][text2pickle.py][line:64][INFO] Ses01F_script03_1_F020: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:29:31,711][text2pickle.py][line:64][INFO] Ses02F_impro07_F029: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:29:32,393][text2pickle.py][line:64][INFO] Ses02F_impro07_M010: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:30:14,946][text2pickle.py][line:64][INFO] Ses03F_script03_1_F000: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:30:50,116][text2pickle.py][line:64][INFO] Ses04M_impro04_F017: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:30:58,610][text2pickle.py][line:64][INFO] Ses04F_impro03_F052: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:06,601][text2pickle.py][line:64][INFO] Ses04F_impro07_F036: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:07,299][text2pickle.py][line:64][INFO] Ses04F_impro07_F064: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:07,334][text2pickle.py][line:64][INFO] Ses04F_impro07_F065: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:33,639][text2pickle.py][line:64][INFO] Ses05F_impro06_F004: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:34,041][text2pickle.py][line:64][INFO] Ses05F_impro06_F015: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:34,375][text2pickle.py][line:64][INFO] Ses05F_impro06_F024: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:34,483][text2pickle.py][line:64][INFO] Ses05F_impro06_F027: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:38,013][text2pickle.py][line:64][INFO] Ses05F_impro07_F033: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:51,939][text2pickle.py][line:64][INFO] Ses05F_impro03_F036: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:52,084][text2pickle.py][line:64][INFO] Ses05F_impro03_F041: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:52,631][text2pickle.py][line:64][INFO] Ses05F_impro03_F060: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:53,336][text2pickle.py][line:64][INFO] Ses05F_impro03_M035: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:53,450][text2pickle.py][line:64][INFO] Ses05F_impro03_M038: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:53,926][text2pickle.py][line:64][INFO] Ses05F_impro03_M060: \n",
      "\n",
      "Note: Blank transcript for: [2022-02-15 11:31:57,685][text2pickle.py][line:64][INFO] Ses05M_impro02_F024: \n",
      "\n",
      "Formatted ground truth saved to ./OutputFiles/groundtruth_IEMOCAP.csv\n"
     ]
    }
   ],
   "source": [
    "# Open the input file and process each line\n",
    "with open(input_file, mode=\"r\", encoding=\"utf-8\") as infile:\n",
    "    with open(output_csv, mode=\"w\", encoding=\"utf-8\") as outfile:\n",
    "        \n",
    "        # Manually write header\n",
    "        outfile.write(\"ID,Transcription\\n\")\n",
    "        \n",
    "        for line in infile:\n",
    "            # Use regex to extract the ID and transcript\n",
    "            match = re.search(r\"(\\S+): (.+)\", line)\n",
    "            if match:\n",
    "                # Extract ID and transcript\n",
    "                utterance_id = match.group(1)  # The ID (e.g., Ses01F_script01_3_F000)\n",
    "                transcript = match.group(2).strip()  # The transcript\n",
    "\n",
    "                # Write the formatted line to the output file\n",
    "                outfile.write(f\"{utterance_id},{transcript}\\n\")\n",
    "                \n",
    "            # Audio has no transcript\n",
    "            else:\n",
    "                print(f\"Note: Blank transcript for: {line}\")\n",
    "                match_2 = re.search(r\"\\[INFO\\]\\s+(\\S+:)\", line)\n",
    "                utterance_id = match_2.group(1)\n",
    "                outfile.write(f\"{utterance_id[:-1]}, \\n\") #[:-1] prevents writing the \":\"\n",
    "\n",
    "print(f\"Formatted ground truth saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6bd350-52c4-42e6-ad9e-0a251cfd1a56",
   "metadata": {},
   "source": [
    "## Formats ONE .csv file to .txt file for use in compute_wer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "322ba4d1-f645-4e12-bae4-f20e75f011f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input and output file paths\n",
    "input_csv = \"predictions.csv\"  # Replace with your CSV file path\n",
    "output_txt = \"predictions.txt\"  # Replace with your desired TXT file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70b89532-5680-40e9-b617-f53228a3ac98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted predictions.csv to predictions.txt\n"
     ]
    }
   ],
   "source": [
    "# Open the CSV file and read its content\n",
    "def convert_csv_to_txt(input_csv, output_txt):\n",
    "    with open(input_csv, mode=\"r\", encoding=\"utf-8\") as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        header = next(csv_reader, None)  # Skip header if present\n",
    "        with open(output_txt, mode=\"w\", encoding=\"utf-8\") as txt_file:\n",
    "            for row in csv_reader:\n",
    "                # Combine ID and Transcript with a space separator\n",
    "                txt_file.write(f\"{row[0]} {row[1]}\\n\")\n",
    "    \n",
    "convert_csv_to_txt(input_csv, output_txt)\n",
    "print(f\"Converted {input_csv} to {output_txt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed2bd04-6d7b-42cd-9020-444c1820b2f3",
   "metadata": {},
   "source": [
    "## Formats ALL .csv file to .txt file for use in compute_wer.py for each fold folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7539762e-aaeb-48ed-9205-6682a1ac5b17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_directory = \"./whisper-tiny-en+Twitter-roBERTa-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3020805b-d501-40ea-9420-2b9ef327900f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: ./whisper-tiny-en+Twitter-roBERTa-base\\fold_0\\predictions.csv\n",
      "Done: ./whisper-tiny-en+Twitter-roBERTa-base\\fold_1\\predictions.csv\n",
      "Done: ./whisper-tiny-en+Twitter-roBERTa-base\\fold_2\\predictions.csv\n",
      "Done: ./whisper-tiny-en+Twitter-roBERTa-base\\fold_3\\predictions.csv\n",
      "Done: ./whisper-tiny-en+Twitter-roBERTa-base\\fold_4\\predictions.csv\n",
      "Done: ./whisper-tiny-en+Twitter-roBERTa-base\\fold_5\\predictions.csv\n",
      "Done: ./whisper-tiny-en+Twitter-roBERTa-base\\fold_6\\predictions.csv\n",
      "Done: ./whisper-tiny-en+Twitter-roBERTa-base\\fold_7\\predictions.csv\n",
      "Done: ./whisper-tiny-en+Twitter-roBERTa-base\\fold_8\\predictions.csv\n",
      "Done: ./whisper-tiny-en+Twitter-roBERTa-base\\fold_9\\predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Iterate over all folders in the base directory\n",
    "for folder_name in os.listdir(base_directory):\n",
    "    folder_path = os.path.join(base_directory, folder_name)\n",
    "    # Check if the folder matches the \"fold_{number}\" pattern\n",
    "    if os.path.isdir(folder_path) and folder_name.startswith(\"fold_\"):\n",
    "        input_csv = os.path.join(folder_path, \"predictions.csv\")\n",
    "        output_txt = os.path.join(folder_path, \"predictions.txt\")\n",
    "        # Check if the CSV file exists\n",
    "        if os.path.exists(input_csv):\n",
    "            convert_csv_to_txt(input_csv, output_txt)\n",
    "            print(f\"Done: {input_csv}\")\n",
    "        else:\n",
    "            print(f\"No prediction.csv found in {folder_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78002816-8321-419a-8a3a-802e9ad52620",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AAI3001",
   "language": "python",
   "name": "aai3001"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
